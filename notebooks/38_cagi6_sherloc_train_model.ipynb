{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c81e96-6b41-41fa-80a6-6360c482eb58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "### Narval\n",
    "\n",
    "```bash\n",
    "export NOTEBOOK_PATH=\"$(realpath 38_cagi6_sherloc_train_model.ipynb)\"\n",
    "\n",
    "\n",
    "export FEATURES_TO_USE=\"msa-proteinsolver-protbert-rosetta_ddg-alphafold\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "\n",
    "export FEATURES_TO_USE=\"proteinsolver-protbert-rosetta_ddg-alphafold\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"msa-protbert-rosetta_ddg-alphafold\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"msa-proteinsolver-rosetta_ddg-alphafold\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"msa-proteinsolver-protbert-alphafold\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"msa-proteinsolver-protbert-rosetta_ddg\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "\n",
    "export FEATURES_TO_USE=\"\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"msa\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"proteinsolver\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"protbert\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"rosetta_ddg\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"alphafold\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3-${FEATURES_TO_USE} --time 48:00:00 --ntasks-per-node 40 --mem=80G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "```\n",
    "\n",
    "### Graham\n",
    "\n",
    "```bash\n",
    "export NOTEBOOK_PATH=\"$(realpath 38_cagi6_sherloc_train_model.ipynb)\"\n",
    "\n",
    "export FEATURES_TO_USE=\"proteinsolver-protbert-rosetta_ddg-alphafold\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3_all --time 24:00:00 --ntasks-per-node 44 --mem=180G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"proteinsolver-protbert-rosetta_ddg-alphafold-alphafold_change\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=el3_all_afchange --time 24:00:00 --ntasks-per-node 44 --mem=180G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "\n",
    "export FEATURES_TO_USE=\"proteinsolver\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=proteinsolver --time 24:00:00 --ntasks-per-node 44 --mem=180G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"protbert\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=protbert --time 24:00:00 --ntasks-per-node 44 --mem=180G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"rosetta_ddg\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=rosetta_ddg --time 24:00:00 --ntasks-per-node 44 --mem=180G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"alphafold_wt\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=alphafold_wt --time 24:00:00 --ntasks-per-node 44 --mem=180G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "export FEATURES_TO_USE=\"alphafold_change\"\n",
    "sbatch --export NOTEBOOK_PATH,FEATURES_TO_USE --job-name=alphafold_change --time 24:00:00 --ntasks-per-node 44 --mem=180G --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec276dec-6afa-4b57-bbfc-a11e04a8767e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f4edf-ca04-4bef-b5c9-a6d402f7570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "import tempfile\n",
    "import uuid\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import elaspic2 as el2\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as olgb\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from scipy import stats\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b0792-00b7-44be-9257-a554f95bd602",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 1000)\n",
    "pd.set_option(\"max_rows\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0ca05-c038-414f-ba84-b2ae8013088b",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907ef01-3df6-40bc-a669-b74c41b81200",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    UNIQUE_ID\n",
    "except NameError:\n",
    "    UNIQUE_ID = str(uuid.uuid4())[:8]\n",
    "\n",
    "UNIQUE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1faee-9f6a-40d8-8819-272b1c9837bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path(\"38_cagi6_sherloc_train_model\").resolve()\n",
    "NOTEBOOK_DIR.joinpath(UNIQUE_ID).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241c662-f4d3-4fff-804a-21ee7ff90582",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = str(NOTEBOOK_DIR.parents[1].joinpath(\"src\"))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.insert(0, src_dir)\n",
    "\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4dcea8-9978-4832-ba96-5e61c39d769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_TO_USE = os.getenv(\"FEATURES_TO_USE\")\n",
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "\n",
    "FEATURES_TO_USE, TASK_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c288a-b31b-414c-bff7-3bb66ac8a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = TASK_ID is None\n",
    "\n",
    "if DEBUG:\n",
    "    FEATURES_TO_USE = \"protbert\"\n",
    "else:\n",
    "    assert FEATURES_TO_USE is not None\n",
    "\n",
    "FEATURES_TO_USE, DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f436ee-fbcc-44dd-b1b4-f910a13df52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureClass(enum.Enum):\n",
    "    msa = \"msa\"\n",
    "    proteinsolver = \"proteinsolver\"\n",
    "    protbert = \"protbert\"\n",
    "    rosetta_ddg = \"rosetta_ddg\"\n",
    "    alphafold = \"alphafold\"\n",
    "    alphafold_change = \"alphafold_change\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ab401-88b6-45b1-b555-e38490f81484",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = [FeatureClass(fc) for fc in FEATURES_TO_USE.split(\"-\") if fc]\n",
    "\n",
    "features_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b610c9-4067-41e5-90bd-3e5810f636ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_info_file = NOTEBOOK_DIR.joinpath(f\"{FEATURES_TO_USE}.txt\")\n",
    "feature_set_info_file.touch()\n",
    "\n",
    "feature_set_info_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd00941b-a3df-48d4-864c-bef984a8cd3b",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eef855-210a-46c5-b48a-6e25b8986b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_1 = NOTEBOOK_DIR.parent.joinpath(\n",
    "    \"37_cagi6_sherloc_combine_results\", \"combined-results.parquet\"\n",
    ")\n",
    "\n",
    "input_file_2 = NOTEBOOK_DIR.parent.joinpath(\n",
    "    \"37_humsavar_combine_results\", \"combined-results.parquet\"\n",
    ")\n",
    "\n",
    "input_file_1, input_file_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d4005-e180-4ade-8ae7-a14237eb41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1_df = pq.read_table(input_file_1).to_pandas()\n",
    "result_2_df = pq.read_table(input_file_2).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81640a99-ca78-418d-8a81-2c7ed7e657bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1_df[\"protein_id\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd13567-1196-43c1-81ea-ea07f1141631",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1_df = result_1_df.dropna(subset=[\"protein_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b5243-b97f-40cd-a099-a42f6c3c673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = set(result_1_df) & set(result_2_df)\n",
    "mismatched_columns = set(result_1_df) ^ set(result_2_df)\n",
    "\n",
    "len(common_columns), len(mismatched_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6ba63-d1b1-494d-97ff-a4ee6b30ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3c81d-e38e-421c-83e3-bb0b46929788",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [result_1_df[common_columns], result_2_df[common_columns]],\n",
    "    ignore_index=True,\n",
    ")\n",
    "del result_1_df, result_2_df\n",
    "\n",
    "display(result_df.head(2))\n",
    "print(len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8e99e-ccd9-4c28-8613-c3bde79aefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_map = {\n",
    "    \"Uncertain significance\": 0,\n",
    "    \"US\": 0,\n",
    "    \"Likely benign\": -1,\n",
    "    \"Benign\": -1,\n",
    "    \"LB/B\": -1,\n",
    "    \"Likely pathogenic\": 1,\n",
    "    \"Pathogenic\": 1,\n",
    "    \"LP/P\": 1,\n",
    "}\n",
    "\n",
    "result_df[\"effect_score\"] = result_df[\"effect\"].map(effect_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66edf8-84c4-4258-9a9b-f9086248ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"effect_score\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a022f7-5f44-4505-9d5b-7f2086b984aa",
   "metadata": {},
   "source": [
    "## Train ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d477fa31-30ac-4db5-b7f3-f063ed962d47",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32d346-15dc-44b4-81d0-66c9b939dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_features = []\n",
    "\n",
    "if FeatureClass.msa in features_to_use:\n",
    "    scalar_features += [c for c in result_df if c.startswith(\"msa\")]\n",
    "\n",
    "if FeatureClass.protbert in features_to_use:\n",
    "    scalar_features += [\n",
    "        \"protbert_core_score_wt\",\n",
    "        \"protbert_core_score_change\",\n",
    "    ]\n",
    "\n",
    "if FeatureClass.proteinsolver in features_to_use:\n",
    "    scalar_features += [\n",
    "        \"proteinsolver_core_score_wt\",\n",
    "        \"proteinsolver_core_score_change\",\n",
    "    ]\n",
    "\n",
    "if FeatureClass.rosetta_ddg in features_to_use:\n",
    "    scalar_features += [c for c in result_df if c.startswith(\"rosetta\")]\n",
    "\n",
    "if FeatureClass.alphafold in features_to_use:\n",
    "    scalar_features += [c for c in result_df if c.startswith(\"alphafold_core_score\")]\n",
    "\n",
    "if FeatureClass.alphafold_change in features_to_use:\n",
    "    scalar_features += [\n",
    "        \"alphafold_core_scores_residue_plddt_change\",\n",
    "    ]\n",
    "\n",
    "\n",
    "with NOTEBOOK_DIR.joinpath(UNIQUE_ID, \"scalar-features.json\").open(\"wt\") as fout:\n",
    "    json.dump(scalar_features, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fca4d3-4f90-4f63-b93f-91bc81b101c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_features = [\n",
    "    \"aa_wt_onehot\",\n",
    "    \"aa_mut_onehot\",\n",
    "]\n",
    "\n",
    "if FeatureClass.protbert in features_to_use:\n",
    "    vector_features += [\n",
    "        \"protbert_core_features_residue_wt\",\n",
    "        \"protbert_core_features_residue_change\",\n",
    "    ]\n",
    "\n",
    "if FeatureClass.proteinsolver in features_to_use:\n",
    "    vector_features += [\n",
    "        \"proteinsolver_core_features_residue_wt\",\n",
    "        \"proteinsolver_core_features_residue_change\",\n",
    "    ]\n",
    "\n",
    "if FeatureClass.alphafold in features_to_use:\n",
    "    vector_features += [\n",
    "        c\n",
    "        for c in result_df\n",
    "        if c.startswith(\"alphafold\") and not c.startswith(\"alphafold_core_score\")\n",
    "    ]\n",
    "\n",
    "if FeatureClass.alphafold_change in features_to_use:\n",
    "    vector_features += [\n",
    "        \"alphafold_core_features_residue_experimentally_resolved_change\",  # 0.11 [37]\n",
    "        \"alphafold_core_features_residue_predicted_lddt_change\",  # 0.04 [50]\n",
    "        \"alphafold_core_features_residue_msa_first_row_change\",  # 0.21 [256]\n",
    "        \"alphafold_core_features_residue_single_change\",  # 0.15 [384]\n",
    "        \"alphafold_core_features_residue_structure_module_change\",  # 0.05 [384]\n",
    "    ]\n",
    "\n",
    "with NOTEBOOK_DIR.joinpath(UNIQUE_ID, \"vector-features.json\").open(\"wt\") as fout:\n",
    "    json.dump(vector_features, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642f67d-fcf8-4378-be7b-240cbb24acf7",
   "metadata": {},
   "source": [
    "### Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c22e1-9618-434f-b401-3f90e2dc46bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df = (\n",
    "    result_df.dropna(\n",
    "        subset=scalar_features\n",
    "        + vector_features\n",
    "        + [\n",
    "            \"effect_score\",\n",
    "        ]\n",
    "    )\n",
    "    .drop_duplicates(subset=[\"protein_id\", \"mutation\"])\n",
    "    .sort_values(\"protein_id\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "training_df = training_df[training_df[\"effect_score\"] != 0]\n",
    "\n",
    "del result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41576f7-6ff6-4859-b179-6d85b8df9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df[\"protein_id\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da752320-007e-48ca-bd35-c016b9fd3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, column_group_map, expanded_vector_features = helpers.expand_arrays(\n",
    "    training_df, vector_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0118587-e87d-451e-a0da-6c43561988fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NOTEBOOK_DIR.joinpath(UNIQUE_ID, \"column-group-map.json\").open(\"wt\") as fout:\n",
    "    json.dump(column_group_map, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6676ab-1771-4fc5-a14a-ea0df4ab8caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# protein_map = {k: i for i, k in enumerate(df[\"protein_id\"].unique())}\n",
    "# groups = df[\"protein_id\"].map(protein_map).values\n",
    "\n",
    "value_counts = training_df[\"protein_id\"].value_counts()\n",
    "groups = training_df[\"protein_id\"].drop_duplicates().map(value_counts).values\n",
    "\n",
    "protein_ids = training_df[\"protein_id\"]\n",
    "\n",
    "X = training_df[scalar_features + expanded_vector_features].values\n",
    "# X = X[:, important_features]\n",
    "\n",
    "# low_confidence_mask = df[\"effect_score\"] == 0\n",
    "\n",
    "y = (training_df[\"effect_score\"] > 0).values.astype(int)\n",
    "# y[low_confidence_mask] = (df[low_confidence_mask][\"el2_score\"] > 2).values.astype(int)\n",
    "# y = df[\"effect_score\"].values\n",
    "\n",
    "# weights = np.ones(len(df), dtype=np.float64)\n",
    "# weights[df[\"effect_score\"] == 1] = 0.5\n",
    "# weights[df[\"effect_score\"] == -1] = 0.5\n",
    "# weights[low_confidence_mask] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0417f3ad-ff8c-46ed-a74f-5b3a89ae4673",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df[\"effect_score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f84190-549f-4792-8ff2-4affa71e237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_df)  # 84057"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268b00d-6f53-489a-a8aa-8141622fcec1",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe1ca1-f5ef-42c1-82d9-0edad9fdd82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_PARAM = {\n",
    "    \"objective\": \"binary\",\n",
    "    #     \"metric\": \"binary_logloss\",\n",
    "    \"metric\": \"average_precision\",\n",
    "    # \"is_unbalance\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f2323-0afa-4eb4-937d-2e77e6a2b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(X, y, param, protein_ids, n_splits=6, progressbar=False):\n",
    "    models = []\n",
    "    preds = np.ones(len(y), dtype=np.float64) * np.nan\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    for train_index, test_index in tqdm(\n",
    "        gkf.split(X, y, groups=protein_ids),\n",
    "        total=n_splits,\n",
    "        disable=not progressbar,\n",
    "    ):\n",
    "        X_training, X_testing = X[train_index], X[test_index]\n",
    "        y_training, y_testing = y[train_index], y[test_index]\n",
    "        # weights_training, weights_testing = weights[train_index], weights[test_index]\n",
    "\n",
    "        dtrain = lgb.Dataset(\n",
    "            X_training,\n",
    "            label=y_training,\n",
    "            # weight=weights_training,\n",
    "        )\n",
    "        model = lgb.train(param, dtrain)\n",
    "        preds[test_index] = model.predict(X_testing)\n",
    "        models.append(model)\n",
    "    return models, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde5332-4896-4fd2-bdee-cf1b8f9f4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y):\n",
    "    param = CONST_PARAM | {\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 64),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 60),\n",
    "    }\n",
    "    models, preds = training_loop(X, y, param, protein_ids)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = metrics.accuracy_score(y, pred_labels)\n",
    "    auc = metrics.roc_auc_score(y, preds)\n",
    "    precision = metrics.average_precision_score(y, preds)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af684e6-ff75-4540-ac7c-81487cebd7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X, label=y, group=groups)\n",
    "\n",
    "with tempfile.TemporaryDirectory() as model_dir:\n",
    "    tuner = olgb.LightGBMTunerCV(\n",
    "        CONST_PARAM | {\"verbosity\": -1},\n",
    "        dtrain,\n",
    "        verbose_eval=200,\n",
    "        early_stopping_rounds=250,\n",
    "        folds=GroupKFold(n_splits=6),\n",
    "        num_boost_round=100,  # 1000\n",
    "        model_dir=model_dir,\n",
    "        time_budget=60 * 60 * 3,\n",
    "        return_cvbooster=True,\n",
    "    )\n",
    "    tuner.run()\n",
    "    booster = tuner.get_best_booster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb86b3b-89ff-4659-9d18-52650dc9a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = tuner.best_params\n",
    "\n",
    "print(tuner.best_score)\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa394afb-ad24-4544-99e7-b082947813bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NOTEBOOK_DIR.joinpath(UNIQUE_ID, \"best-parameters-starting.json\").open(\n",
    "    \"wt\"\n",
    ") as fout:\n",
    "    json.dump(param, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c57b7-29eb-4984-bb8c-36129a227603",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bst_idx, bst in enumerate(booster.boosters):\n",
    "    bst.save_model(\n",
    "        str(NOTEBOOK_DIR.joinpath(UNIQUE_ID, f\"model-starting-{bst_idx}.txt\"))\n",
    "    )\n",
    "\n",
    "# _ = dtrain.save_binary(str(NOTEBOOK_DIR.joinpath(UNIQUE_ID, \"training-data.bin\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2523fa04-0c78-46cb-b7ef-b07c34bfdfe5",
   "metadata": {},
   "source": [
    "### Feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ae48d-220f-41a0-995d-7c82e63ddb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_elimination_stats_file = NOTEBOOK_DIR.joinpath(\n",
    "    UNIQUE_ID, \"feature-elimination-stats.pickle\"\n",
    ")\n",
    "feature_elimination_stats_file.touch()\n",
    "\n",
    "\n",
    "features = scalar_features + expanded_vector_features\n",
    "print(f\"Starting with {len(features)} features.\")\n",
    "\n",
    "\n",
    "fe_round = -1\n",
    "fe_round_stats = []\n",
    "best_params = {\n",
    "    cutoff: None for cutoff in [3500, 2000, 1000, 500] if X.shape[1] > cutoff\n",
    "}\n",
    "highest_precision = None\n",
    "while features:\n",
    "    fe_round += 1\n",
    "\n",
    "    X = training_df[features].values\n",
    "\n",
    "    # Retune parameters\n",
    "    for cutoff, best_param in list(best_params.items()):\n",
    "        if X.shape[1] < cutoff and best_param is None:\n",
    "            dtrain = lgb.Dataset(X, label=y, group=groups)\n",
    "            tuner = olgb.LightGBMTunerCV(\n",
    "                CONST_PARAM | {\"verbosity\": -1},\n",
    "                dtrain,\n",
    "                verbose_eval=200,\n",
    "                early_stopping_rounds=250,\n",
    "                folds=GroupKFold(n_splits=6),\n",
    "                num_boost_round=100,  # 1000\n",
    "                time_budget=60 * 60 * 3,\n",
    "            )\n",
    "            tuner.run()\n",
    "            best_params[cutoff] = tuner.best_params\n",
    "            param = tuner.best_params\n",
    "            with NOTEBOOK_DIR.joinpath(\n",
    "                UNIQUE_ID, f\"best-parameters-{cutoff}.json\"\n",
    "            ).open(\"wt\") as fout:\n",
    "                json.dump(param, fout)\n",
    "\n",
    "    # Re-train models\n",
    "    models, preds = training_loop(X, y, param, protein_ids, progressbar=True)\n",
    "\n",
    "    # Calculate model statistics\n",
    "    corr = stats.spearmanr(y, preds)\n",
    "    auc = metrics.roc_auc_score(y, preds)\n",
    "    precision = metrics.average_precision_score(y, preds)\n",
    "\n",
    "    # Save stats\n",
    "    round_stats = (\n",
    "        fe_round,\n",
    "        corr[0],\n",
    "        auc,\n",
    "        precision,\n",
    "        len(features),\n",
    "        features,\n",
    "    )\n",
    "    print(round_stats[:-1])\n",
    "    fe_round_stats.append(round_stats)\n",
    "    shutil.copyfile(\n",
    "        feature_elimination_stats_file,\n",
    "        feature_elimination_stats_file.with_suffix(\".pickle.bak\"),\n",
    "    )\n",
    "    with feature_elimination_stats_file.open(\"wb\") as fout:\n",
    "        pickle.dump(fe_round_stats, fout, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Save best models\n",
    "    if highest_precision is None or precision > highest_precision:\n",
    "        highest_precision = precision\n",
    "        for model_idx, model in enumerate(models):\n",
    "            model.save_model(\n",
    "                str(\n",
    "                    NOTEBOOK_DIR.joinpath(\n",
    "                        UNIQUE_ID, f\"model-{fe_round}-{model_idx}.txt\"\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Find new features to eliminate\n",
    "    feature_importance_split = np.vstack(\n",
    "        [model.feature_importance(\"split\") for model in models]\n",
    "    ).sum(axis=0)\n",
    "    feature_importance_gain = np.vstack(\n",
    "        [model.feature_importance(\"gain\") for model in models]\n",
    "    ).sum(axis=0)\n",
    "\n",
    "    feature_df = pd.DataFrame(\n",
    "        {\n",
    "            \"feature_name\": features,\n",
    "            \"feature_importance_split\": feature_importance_split,\n",
    "            \"feature_importance_gain\": feature_importance_gain,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if (feature_df[\"feature_importance_split\"] == 0).any():\n",
    "        feature_df = feature_df[feature_df[\"feature_importance_split\"] != 0]\n",
    "    else:\n",
    "        num_features_to_drop = max(1, len(feature_df) // 100)\n",
    "        feature_df = feature_df.sort_values(\n",
    "            [\"feature_importance_split\", \"feature_importance_gain\"], ascending=True\n",
    "        ).iloc[num_features_to_drop:]\n",
    "\n",
    "    features = feature_df[\"feature_name\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5609f-c947-419a-9917-5a021ffb0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651b660-bdcb-48f4-a7ae-34011a1e6331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
