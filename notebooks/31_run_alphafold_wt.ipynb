{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Calculate features using [AlphaFold](https://github.com/deepmind/alphafold) (for the wildtype protein only).\n",
    "\n",
    "```bash\n",
    "export NOTEBOOK_PATH=\"$(realpath 31_run_alphafold_wt.ipynb)\"\n",
    "export DATASET_NAME=\"humsavar\"\n",
    "export DATASET_PATH=\"30_humsavar/humsavar-gby-protein-waln.parquet\"\n",
    "export ORIGINAL_ARRAY_TASK_COUNT=12557\n",
    "\n",
    "sbatch --export NOTEBOOK_PATH,DATASET_NAME,DATASET_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=1-9999 --time 3:00:00 --gres=gpu:p100:1 --mem=18G ../scripts/run_notebook_gpu.sh\n",
    "\n",
    "export ARRAY_TASK_OFFSET=10000\n",
    "sbatch --export NOTEBOOK_PATH,DATASET_NAME,DATASET_PATH,ORIGINAL_ARRAY_TASK_COUNT,ARRAY_TASK_OFFSET --array=0-1000 --time 3:00:00 --gres=gpu:v100l:1 --mem=32G ../scripts/run_notebook_gpu.sh\n",
    "\n",
    "export ARRAY_TASK_OFFSET=10000\n",
    "sbatch --export NOTEBOOK_PATH,DATASET_NAME,DATASET_PATH,ORIGINAL_ARRAY_TASK_COUNT,ARRAY_TASK_OFFSET --array=1000-2557 --time 24:00:00 --gres=gpu:v100l:1 --mem=46G ../scripts/run_notebook_gpu.sh\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TF_FORCE_UNIFIED_MEMORY=1\n",
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import kmbio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from elaspic2.plugins.alphafold import AlphaFold, AlphaFoldAnalyzeError, AlphaFoldBuildError\n",
    "from jax.lib import xla_bridge\n",
    "from kmbio import PDB\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path(\"31_run_alphafold_wt\").resolve()\n",
    "NOTEBOOK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (slurm_tmpdir := os.getenv(\"SLURM_TMPDIR\")) is not None:\n",
    "    os.environ[\"TMPDIR\"] = slurm_tmpdir\n",
    "\n",
    "print(tempfile.gettempdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = os.getenv(\"DATASET_NAME\")\n",
    "DATASET_PATH = os.getenv(\"DATASET_PATH\")\n",
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "ARRAY_TASK_OFFSET = int(os.getenv(\"ARRAY_TASK_OFFSET\", \"0\"))\n",
    "\n",
    "TASK_ID = (int(TASK_ID) + ARRAY_TASK_OFFSET) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "DATASET_NAME, DATASET_PATH, TASK_ID, TASK_COUNT, ARRAY_TASK_OFFSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = TASK_ID is None\n",
    "\n",
    "if DEBUG:\n",
    "#     DATASET_NAME = \"cagi6-sherloc\"\n",
    "#     DATASET_PATH = str(\n",
    "#         NOTEBOOK_DIR.parent.joinpath(\"30_cagi6_sherloc\", \"input-data-gby-protein.parquet\")\n",
    "#     )\n",
    "#     TASK_ID = 3500\n",
    "#     TASK_COUNT = 4182\n",
    "    DATASET_NAME = \"humsavar\"\n",
    "    DATASET_PATH = str(\n",
    "        NOTEBOOK_DIR.parent.joinpath(\"30_humsavar\", \"humsavar-gby-protein-waln.parquet\")\n",
    "    )\n",
    "    TASK_ID = 10000\n",
    "    TASK_COUNT = 12557\n",
    "else:\n",
    "    assert DATASET_NAME is not None\n",
    "    assert DATASET_PATH is not None\n",
    "    DATASET_PATH = Path(DATASET_PATH).expanduser().resolve()\n",
    "    assert TASK_ID is not None\n",
    "    assert TASK_COUNT is not None\n",
    "\n",
    "DATASET_NAME, DATASET_PATH, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCyTzII-HD1t",
    "outputId": "92f63199-1727-48d3-cb4b-6ff798fa75b6"
   },
   "outputs": [],
   "source": [
    "device = xla_bridge.get_backend().platform\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = NOTEBOOK_DIR.joinpath(DATASET_NAME, f\"shard-{TASK_ID}-of-{TASK_COUNT}.parquet\")\n",
    "output_file.parent.mkdir(exist_ok=True)\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_file.is_file():\n",
    "    raise Exception(\"Already finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlphaFold.load_model(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = pq.ParquetFile(DATASET_PATH)\n",
    "\n",
    "pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TASK_COUNT == pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pfile.read_row_group(TASK_ID - 1).to_pandas(integer_object_nulls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(input_df.head(2))\n",
    "print(len(input_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_id_column = None\n",
    "\n",
    "for col in [\"protein_id\", \"uniprot_id\"]:\n",
    "    if col in input_df:\n",
    "        protein_id_column = col\n",
    "        \n",
    "assert protein_id_column is not None\n",
    "protein_id_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tup = next(input_df.itertuples(index=False))\n",
    "\n",
    "iterable_fields = []\n",
    "for field in tup._fields:\n",
    "    if field in [protein_id_column]:\n",
    "        continue\n",
    "    try:\n",
    "        if len(getattr(tup, field)) == len(tup.mutation):\n",
    "            iterable_fields.append(field)\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "iterable_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    for field in iterable_fields:\n",
    "        input_df[field] = input_df[field].str[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mutation(mutation):\n",
    "    aa = \"GVALICMFWPDESTYQNKRH\"\n",
    "    if re.search(f\"^[{aa}][1-9]+[0-9]*[{aa}]$\", mutation) is None:\n",
    "        print(f\"Skipping mutation {mutation} because it appears to be malformed.\")\n",
    "        return False\n",
    "\n",
    "    if mutation[0] == mutation[-1]:\n",
    "        print(\n",
    "            f\"Skipping mutation {mutation} because the wildtype and mutant residues are the same.\"\n",
    "        )\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_embeddings(predictions):\n",
    "    return {\n",
    "        \"plddt\": pa.array([predictions[\"plddt\"]]),\n",
    "        \"max_predicted_aligned_error\": pa.array(\n",
    "            [predictions[\"max_predicted_aligned_error\"].item()]\n",
    "        ),\n",
    "        \"ptm\": pa.array([predictions[\"ptm\"].item()]),\n",
    "        #\n",
    "        \"experimentally_resolved\": pa.array(\n",
    "            [predictions[\"experimentally_resolved\"][\"logits\"].to_py().tolist()]\n",
    "        ),\n",
    "        \"predicted_lddt\": pa.array([predictions[\"predicted_lddt\"][\"logits\"].to_py().tolist()]),\n",
    "        #\n",
    "        \"msa_first_row\": pa.array(\n",
    "            [predictions[\"representations\"][\"msa_first_row\"].to_py().tolist()]\n",
    "        ),\n",
    "        \"single\": pa.array([predictions[\"representations\"][\"single\"].to_py().tolist()]),\n",
    "        \"structure_module\": pa.array(\n",
    "            [predictions[\"representations\"][\"structure_module\"].to_py().tolist()]\n",
    "        ),\n",
    "        # Pairwise metrics\n",
    "        \"distogram\": pa.array([data.predictions[\"distogram\"][\"logits\"].to_py().tolist()]),\n",
    "        \"distogram_bin_edges\": pa.array(\n",
    "            [data.predictions[\"distogram\"][\"bin_edges\"].to_py().tolist()]\n",
    "        ),\n",
    "        \"masked_msa\": pa.array([data.predictions[\"masked_msa\"][\"logits\"].to_py().tolist()]),\n",
    "        \"predicted_aligned_error\": pa.array([data.predictions[\"predicted_aligned_error\"].tolist()]),\n",
    "        \"aligned_confidence_probs\": pa.array(\n",
    "            [data.predictions[\"aligned_confidence_probs\"].tolist()]\n",
    "        ),\n",
    "        \"msa\": pa.array([data.predictions[\"representations\"][\"msa\"].to_py().tolist()]),\n",
    "        \"pair\": pa.array([data.predictions[\"representations\"][\"pair\"].to_py().tolist()]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(input_df) == 1\n",
    "\n",
    "for tup in tqdm(input_df.itertuples(index=False), total=len(input_df)):\n",
    "    assert all([(len(getattr(tup, field)) == len(tup.mutation)) for field in iterable_fields])\n",
    "\n",
    "    data = AlphaFold.build(tup.sequence, ligand_sequence=None, msa=tup.alignment)\n",
    "\n",
    "    results = {\"protein_id\": pa.array([tup.protein_id])} | predictions_to_embeddings(\n",
    "        data.predictions\n",
    "    )\n",
    "\n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# for tup in tqdm(input_df.itertuples(index=False), total=len(input_df)):\n",
    "#     assert all([(len(getattr(tup, field)) == len(tup.mutation)) for field in iterable_fields])\n",
    "\n",
    "#     data = AlphaFold.build(tup.sequence, ligand_sequence=None, msa=tup.alignment)\n",
    "\n",
    "#     results.setdefault(\"protein_id\", []).append(tup.protein_id)\n",
    "#     for key, value in predictions_to_embeddings(data.predictions).items():\n",
    "#         results.setdefault(key, []).append(value)\n",
    "\n",
    "#     del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pydict(results)\n",
    "del results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    pq.write_table(table, output_file)\n",
    "else:\n",
    "    pq.write_table(table, Path(tempfile.gettempdir(), output_file.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
