{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Calculate features using [AlphaFold](https://github.com/deepmind/alphafold).\n",
    "\n",
    "```bash\n",
    "export NOTEBOOK_PATH=\"$(realpath 31_run_alphafold.ipynb)\"\n",
    "export DATASET_NAME=\"cagi6-sherloc\"\n",
    "export DATASET_PATH=\"30_cagi6_sherloc/input-data-gby-protein.parquet\"\n",
    "export ORIGINAL_ARRAY_TASK_COUNT=4182\n",
    "\n",
    "# === Cedar ===\n",
    "# p100\n",
    "# sbatch --export DATASET_NAME,DATASET_PATH,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=1-1000 --time 24:00:00 --gres=gpu:p100:1 ../scripts/run_notebook_gpu.sh\n",
    "sbatch --export DATASET_NAME,DATASET_PATH,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=1001-2000 --time 24:00:00 --gres=gpu:p100:1 ../scripts/run_notebook_gpu.sh\n",
    "\n",
    "# v100l\n",
    "sbatch --export DATASET_NAME,DATASET_PATH,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=2001-3000 --time 24:00:00 --gres=gpu:v100l:1 ../scripts/run_notebook_gpu.sh\n",
    "sbatch --export DATASET_NAME,DATASET_PATH,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=3001-3800 --time 24:00:00 --gres=gpu:v100l:1 ../scripts/run_notebook_gpu.sh\n",
    "\n",
    "# CPU\n",
    "sbatch --export DATASET_NAME,DATASET_PATH,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=3801-4182 --time 72:00:00 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "\n",
    "\n",
    "# === Graham ===\n",
    "sbatch --export DATASET_NAME,DATASET_PATH,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=1-3500 --time 24:00:00 --gres=gpu:t4:1 ../scripts/run_notebook_gpu.sh\n",
    "sbatch --export DATASET_NAME,DATASET_PATH,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=181-200 --time 24:00:00 --gres=gpu:v100:1 ../scripts/run_notebook_gpu.sh\n",
    "sbatch --export DATASET_NAME,DATASET_PATH,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=201-306 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "\n",
    "\n",
    "sbatch --export DATASET_NAME,DATASET_PATH,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=3,7,9,12,13,14,17,20,25,29,30,31,34,36,37,39 --time 24:00:00 --gres=gpu:v100:1 ../scripts/run_notebook_gpu.sh\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import kmbio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from elaspic2.plugins.alphafold import (\n",
    "    AlphaFold,\n",
    "    AlphaFoldAnalyzeError,\n",
    "    AlphaFoldBuildError,\n",
    ")\n",
    "from jax.lib import xla_bridge\n",
    "from kmbio import PDB\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/scratch/strokach/workspace/elaspic2-cagi6/notebooks/31_run_alphafold_wt')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOTEBOOK_DIR = Path(\"31_run_alphafold_wt\").resolve()\n",
    "NOTEBOOK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp\n"
     ]
    }
   ],
   "source": [
    "if (slurm_tmpdir := os.getenv(\"SLURM_TMPDIR\")) is not None:\n",
    "    os.environ[\"TMPDIR\"] = slurm_tmpdir\n",
    "\n",
    "print(tempfile.gettempdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cagi6-sherloc',\n",
       " '30_cagi6_sherloc/input-data-gby-protein.parquet',\n",
       " None,\n",
       " 4182)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_NAME = os.getenv(\"DATASET_NAME\")\n",
    "DATASET_PATH = os.getenv(\"DATASET_PATH\")\n",
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\n",
    "    \"SLURM_ARRAY_TASK_COUNT\"\n",
    ")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "DATASET_NAME, DATASET_PATH, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cagi6-sherloc',\n",
       " '/scratch/strokach/workspace/elaspic2-cagi6/notebooks/30_cagi6_sherloc/input-data-gby-protein.parquet',\n",
       " 2800,\n",
       " 4182)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEBUG = TASK_ID is None\n",
    "\n",
    "if DEBUG:\n",
    "    DATASET_NAME = \"cagi6-sherloc\"\n",
    "    DATASET_PATH = str(\n",
    "        NOTEBOOK_DIR.parent.joinpath(\n",
    "            \"30_cagi6_sherloc\", \"input-data-gby-protein.parquet\"\n",
    "        )\n",
    "    )\n",
    "    TASK_ID = 2800\n",
    "    TASK_COUNT = 4182\n",
    "else:\n",
    "    assert DATASET_NAME is not None\n",
    "    assert DATASET_PATH is not None\n",
    "    DATASET_PATH = Path(DATASET_PATH).expanduser().resolve()\n",
    "    assert TASK_ID is not None\n",
    "    assert TASK_COUNT is not None\n",
    "\n",
    "DATASET_NAME, DATASET_PATH, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCyTzII-HD1t",
    "outputId": "92f63199-1727-48d3-cb4b-6ff798fa75b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = xla_bridge.get_backend().platform\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/scratch/strokach/workspace/elaspic2-cagi6/notebooks/31_run_alphafold_wt/cagi6-sherloc/shard-2800-of-4182.parquet')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = NOTEBOOK_DIR.joinpath(\n",
    "    DATASET_NAME, f\"shard-{TASK_ID}-of-{TASK_COUNT}.parquet\"\n",
    ")\n",
    "output_file.parent.mkdir(exist_ok=True)\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_file.is_file():\n",
    "    raise Exception(\"Already finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlphaFold.load_model(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4182"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfile = pq.ParquetFile(DATASET_PATH)\n",
    "\n",
    "pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TASK_COUNT == pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pfile.read_row_group(TASK_ID - 1).to_pandas(integer_object_nulls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_id</th>\n",
       "      <th>mutation_id</th>\n",
       "      <th>mutation</th>\n",
       "      <th>effect</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>alignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9NZC9</td>\n",
       "      <td>[NM_014140.3:c.1594C&gt;T, NM_014140.3:c.1762G&gt;T,...</td>\n",
       "      <td>[L532F, A588S, S579L, R644W, R645C, V650I, R65...</td>\n",
       "      <td>[Uncertain significance, Uncertain significanc...</td>\n",
       "      <td>MSLPLTEEQRKKIEENRQKALARRAEKLLAEQHQRTSSGTSIAGNP...</td>\n",
       "      <td>HEADER                                        ...</td>\n",
       "      <td>[&gt;101\\n, MSLPLTEEQRKKIEENRQKALARRAEKLLAEQHQRTS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein_id                                        mutation_id  \\\n",
       "0     Q9NZC9  [NM_014140.3:c.1594C>T, NM_014140.3:c.1762G>T,...   \n",
       "\n",
       "                                            mutation  \\\n",
       "0  [L532F, A588S, S579L, R644W, R645C, V650I, R65...   \n",
       "\n",
       "                                              effect  \\\n",
       "0  [Uncertain significance, Uncertain significanc...   \n",
       "\n",
       "                                            sequence  \\\n",
       "0  MSLPLTEEQRKKIEENRQKALARRAEKLLAEQHQRTSSGTSIAGNP...   \n",
       "\n",
       "                                           structure  \\\n",
       "0  HEADER                                        ...   \n",
       "\n",
       "                                           alignment  \n",
       "0  [>101\\n, MSLPLTEEQRKKIEENRQKALARRAEKLLAEQHQRTS...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "display(input_df.head(2))\n",
    "print(len(input_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mutation_id', 'mutation', 'effect']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = next(input_df.itertuples(index=False))\n",
    "\n",
    "iterable_fields = []\n",
    "for field in tup._fields:\n",
    "    try:\n",
    "        if len(getattr(tup, field)) == len(tup.mutation):\n",
    "            iterable_fields.append(field)\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "iterable_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    for field in iterable_fields:\n",
    "        input_df[field] = input_df[field].str[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mutation(mutation):\n",
    "    aa = \"GVALICMFWPDESTYQNKRH\"\n",
    "    if re.search(f\"^[{aa}][1-9]+[0-9]*[{aa}]$\", mutation) is None:\n",
    "        print(f\"Skipping mutation {mutation} because it appears to be malformed.\")\n",
    "        return False\n",
    "\n",
    "    if mutation[0] == mutation[-1]:\n",
    "        print(\n",
    "            f\"Skipping mutation {mutation} because the wildtype and mutant residues are the same.\"\n",
    "        )\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_embeddings(predictions):\n",
    "    return {\n",
    "        \"plddt\": predictions[\"plddt\"],\n",
    "        \"max_predicted_aligned_error\": predictions[\"max_predicted_aligned_error\"].item(),\n",
    "        \"ptm\": predictions[\"ptm\"].item(),\n",
    "        #\n",
    "        \"experimentally_resolved\": predictions[\"experimentally_resolved\"][\"logits\"].to_py().tolist(),\n",
    "        \"predicted_lddt\": predictions[\"predicted_lddt\"][\"logits\"].to_py().tolist(),\n",
    "        #\n",
    "        \"msa_first_row\": predictions[\"representations\"][\"msa_first_row\"].to_py().tolist(),\n",
    "        \"single\": predictions[\"representations\"][\"single\"].to_py().tolist(),\n",
    "        \"structure_module\": predictions[\"representations\"][\"structure_module\"].to_py().tolist(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3c91865d614ee794ce7256adfa30cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function nearest_neighbor_clusters at 0x2aef79b2ec10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp1o9w91q1.py, line 12)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function nearest_neighbor_clusters at 0x2aef79b2ec10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp1o9w91q1.py, line 12)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function nearest_neighbor_clusters at 0x2aef79b2ec10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp1o9w91q1.py, line 12)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function summarize_clusters at 0x2aef79b2ed30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpkxxp5bgt.py, line 27)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function summarize_clusters at 0x2aef79b2ed30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpkxxp5bgt.py, line 27)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function summarize_clusters at 0x2aef79b2ed30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpkxxp5bgt.py, line 27)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for tup in tqdm(input_df.itertuples(index=False), total=len(input_df)):\n",
    "    assert all(\n",
    "        [(len(getattr(tup, field)) == len(tup.mutation)) for field in iterable_fields]\n",
    "    )\n",
    "\n",
    "    data = AlphaFold.build(tup.sequence, ligand_sequence=None, msa=tup.alignment)\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"protein_id\": tup.protein_id,\n",
    "        }\n",
    "        | predictions_to_embeddings(data.predictions)\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_id</th>\n",
       "      <th>plddt</th>\n",
       "      <th>max_predicted_aligned_error</th>\n",
       "      <th>ptm</th>\n",
       "      <th>experimentally_resolved</th>\n",
       "      <th>predicted_lddt</th>\n",
       "      <th>msa_first_row</th>\n",
       "      <th>single</th>\n",
       "      <th>structure_module</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9NZC9</td>\n",
       "      <td>[31.192487998268913, 27.489300698296564, 30.61...</td>\n",
       "      <td>31.75</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>[[0.014223925769329071, 0.11759003251791, 0.08...</td>\n",
       "      <td>[[-3.9497342109680176, -3.859968423843384, -2....</td>\n",
       "      <td>[[-1.3386276960372925, 2.880795955657959, 2.09...</td>\n",
       "      <td>[[-6.072865009307861, 70.27467346191406, 9.798...</td>\n",
       "      <td>[[0.0007754936814308167, -0.005730725824832916...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein_id                                              plddt  \\\n",
       "0     Q9NZC9  [31.192487998268913, 27.489300698296564, 30.61...   \n",
       "\n",
       "   max_predicted_aligned_error       ptm  \\\n",
       "0                        31.75  0.586611   \n",
       "\n",
       "                             experimentally_resolved  \\\n",
       "0  [[0.014223925769329071, 0.11759003251791, 0.08...   \n",
       "\n",
       "                                      predicted_lddt  \\\n",
       "0  [[-3.9497342109680176, -3.859968423843384, -2....   \n",
       "\n",
       "                                       msa_first_row  \\\n",
       "0  [[-1.3386276960372925, 2.880795955657959, 2.09...   \n",
       "\n",
       "                                              single  \\\n",
       "0  [[-6.072865009307861, 70.27467346191406, 9.798...   \n",
       "\n",
       "                                    structure_module  \n",
       "0  [[0.0007754936814308167, -0.005730725824832916...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "display(results_df.head(2))\n",
    "print(len(results_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    pq.write_table(pa.Table.from_pandas(results_df, preserve_index=False), output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
