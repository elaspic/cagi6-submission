{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c81e96-6b41-41fa-80a6-6360c482eb58",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "```bash\n",
    "export DATASET_NAME=\"humsavar\"\n",
    "# export RUN_ALPHAFOLD_NOTEBOOK_NAME=\"31_run_alphafold_wt\"\n",
    "export RUN_ALPHAFOLD_NOTEBOOK_NAME=\"31_run_alphafold_wt_template\"\n",
    "\n",
    "export NOTEBOOK_PATH=\"$(realpath 32_process_alphafold.ipynb)\"\n",
    "export ORIGINAL_ARRAY_TASK_COUNT=26\n",
    "\n",
    "sbatch --export DATASET_NAME,RUN_ALPHAFOLD_NOTEBOOK_NAME,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=1-9 --ntasks-per-node=32 --time 6:00:00 --mem=240G --account=rrg-pmkim ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "sbatch --export DATASET_NAME,RUN_ALPHAFOLD_NOTEBOOK_NAME,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=10-18 --ntasks-per-node=16 --time 6:00:00 --mem=240G --account=rrg-pmkim ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "sbatch --export DATASET_NAME,RUN_ALPHAFOLD_NOTEBOOK_NAME,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=19-26 --ntasks-per-node=8 --time 6:00:00 --mem=240G --account=rrg-pmkim ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "\n",
    "\n",
    "sbatch --export DATASET_NAME,RUN_ALPHAFOLD_NOTEBOOK_NAME,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=1,2 --ntasks-per-node=32 --time 6:00:00 --mem=240G --account=rrg-pmkim --mail-user=alexey.strokach@kimlab.org ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "sbatch --export DATASET_NAME,RUN_ALPHAFOLD_NOTEBOOK_NAME,NOTEBOOK_PATH,ORIGINAL_ARRAY_TASK_COUNT --array=24 --ntasks-per-node=8 --time 6:00:00 --mem=240G --account=rrg-pmkim --mail-user=alexey.strokach@kimlab.org ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec276dec-6afa-4b57-bbfc-a11e04a8767e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f4edf-ca04-4bef-b5c9-a6d402f7570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import scipy.special as sps\n",
    "from alphafold.common import residue_constants\n",
    "from scipy import stats\n",
    "from sklearn import metrics, model_selection\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b0792-00b7-44be-9257-a554f95bd602",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 1000)\n",
    "pd.set_option(\"max_rows\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0ca05-c038-414f-ba84-b2ae8013088b",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1faee-9f6a-40d8-8819-272b1c9837bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path(\"32_process_alphafold\").resolve()\n",
    "NOTEBOOK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f63ec9-638c-4a72-b07b-e685d07f0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_COUNT = max(1, len(os.sched_getaffinity(0)))\n",
    "\n",
    "CPU_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098cb4b-8cca-46cb-bd74-66b33da836cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\n",
    "    \"SLURM_ARRAY_TASK_COUNT\"\n",
    ")\n",
    "DATASET_NAME = os.getenv(\"DATASET_NAME\")\n",
    "RUN_ALPHAFOLD_NOTEBOOK_NAME = os.getenv(\n",
    "    \"RUN_ALPHAFOLD_NOTEBOOK_NAME\", \"31_run_alphafold_wt_template\"\n",
    ")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "TASK_ID, TASK_COUNT, DATASET_NAME, RUN_ALPHAFOLD_NOTEBOOK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9923a92-e18e-473f-871e-4f00f09ffe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = TASK_ID is None\n",
    "\n",
    "if DEBUG:\n",
    "    TASK_ID = 25\n",
    "    TASK_COUNT = 26\n",
    "    DATASET_NAME = \"humsavar\"\n",
    "    RUN_ALPHAFOLD_NOTEBOOK_NAME = \"31_run_alphafold_wt_template\"\n",
    "else:\n",
    "    assert TASK_ID is not None\n",
    "    assert TASK_COUNT is not None\n",
    "    assert DATASET_NAME is not None\n",
    "    assert RUN_ALPHAFOLD_NOTEBOOK_NAME is not None\n",
    "\n",
    "TASK_ID, TASK_COUNT, DATASET_NAME, RUN_ALPHAFOLD_NOTEBOOK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754bcaa-1b8d-49cd-9e98-a3d7c9b345b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_NAME = \"humsavar\"\n",
    "# DATASET_PATH = str(\n",
    "#     NOTEBOOK_DIR.parent.joinpath(\"30_humsavar\", \"humsavar-gby-protein.parquet\")\n",
    "# )\n",
    "# DATASET_ALN_PATH = str(\n",
    "#     NOTEBOOK_DIR.parent.joinpath(\"30_humsavar\", \"humsavar-gby-protein-waln.parquet\")\n",
    "# )\n",
    "# TASK_COUNT = 612\n",
    "# TASK_COUNT_ALN = 12557\n",
    "\n",
    "# DATASET_NAME, DATASET_PATH, TASK_COUNT, TASK_COUNT_ALN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab21a5-1ab5-43ea-98bf-f53a61ae3d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"humsavar\"\n",
    "DATASET_PATH = str(\n",
    "    NOTEBOOK_DIR.parent.joinpath(\"30_humsavar\", \"humsavar-gby-protein.parquet\")\n",
    ")\n",
    "DATASET_ALN_PATH = str(\n",
    "    NOTEBOOK_DIR.parent.joinpath(\"30_humsavar\", \"humsavar-gby-protein-waln.parquet\")\n",
    ")\n",
    "DATASET_TASK_COUNT = 612\n",
    "DATASET_ALN_TASK_COUNT = 12557\n",
    "\n",
    "DATASET_NAME, DATASET_PATH, DATASET_TASK_COUNT, DATASET_ALN_TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8402d904-1031-4f41-89b2-ad0eb69b9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_RESULT_DIR = NOTEBOOK_DIR.parent.joinpath(RUN_ALPHAFOLD_NOTEBOOK_NAME, DATASET_NAME)\n",
    "\n",
    "AF_RESULT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5383ee-320e-4270-9a39-4c34b55eac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = NOTEBOOK_DIR.joinpath(\n",
    "    DATASET_NAME, AF_RESULT_DIR.parent.name.strip(string.digits + \"_\").replace(\"_\", \"-\")\n",
    ")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd00941b-a3df-48d4-864c-bef984a8cd3b",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bb337-c239-4cfd-8449-5bd25f817ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_files(result_dir, task_count=DATASET_TASK_COUNT):\n",
    "    if \"msa_analysis\" in str(result_dir):\n",
    "        prefix = \"result\"\n",
    "    else:\n",
    "        prefix = \"shard\"\n",
    "\n",
    "    present_files = []\n",
    "    missing_files = []\n",
    "    for i in tqdm(range(1, task_count + 1)):\n",
    "        path = result_dir.joinpath(f\"{prefix}-{i}-of-{task_count}.parquet\")\n",
    "        if path.is_file():\n",
    "            present_files.append(path)\n",
    "        else:\n",
    "            missing_files.append(path)\n",
    "    return present_files, missing_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778fbf7-217c-4262-8d82-e0f20d4c8c4c",
   "metadata": {},
   "source": [
    "### Find finished files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c664b937-279d-4682-991d-7bfce3b1972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_files_cache = output_dir.joinpath(\"file-list.pickle\")\n",
    "\n",
    "present_files_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43591e8-424a-4c88-8cd7-4611c699caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if present_files_cache.is_file():\n",
    "    with present_files_cache.open(\"rb\") as fin:\n",
    "        present_files = pickle.load(fin)\n",
    "else:\n",
    "    present_files, missing_files = get_result_files(\n",
    "        AF_RESULT_DIR, DATASET_ALN_TASK_COUNT\n",
    "    )\n",
    "    assert len(missing_files) == 0\n",
    "    with present_files_cache.open(\"wb\") as fout:\n",
    "        pickle.dump(present_files, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd710c-a7c5-4c7a-b0d8-41e818530a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(present_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d4bfb5-25e5-4845-be61-c2427f0a5544",
   "metadata": {},
   "source": [
    "### Map protein ids to mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f220904-0fe9-4f2b-bd26-bf421f501159",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_mutations_df = pq.read_table(\n",
    "    DATASET_ALN_PATH, columns=[\"protein_id\", \"mutation\", \"effect\"]\n",
    ").to_pandas()\n",
    "\n",
    "assert len(present_files) == len(protein_mutations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5883fe5-9f3f-458e-a1d0-058411fbeae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(protein_mutations_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa48514-9732-4959-9431-027523d64605",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_mutation_lookup = protein_mutations_df.set_index(\"protein_id\")[\n",
    "    \"mutation\"\n",
    "].to_dict()\n",
    "\n",
    "assert len(present_files) == len(protein_mutation_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1b80e-c7f3-4bd7-8a09-9bfb18794df1",
   "metadata": {},
   "source": [
    "### Process AlphaFold embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66132e53-6f7c-4670-9770-536335affca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"protein_id\",\n",
    "    # Sequence\n",
    "    \"single\",\n",
    "    \"experimentally_resolved\",\n",
    "    \"predicted_lddt\",\n",
    "    \"msa_first_row\",\n",
    "    \"structure_module\",\n",
    "    \"max_predicted_aligned_error\",\n",
    "    \"plddt\",\n",
    "    \"ptm\",\n",
    "    # Pairwise\n",
    "    \"pair\",\n",
    "    \"distogram\",\n",
    "    # \"distogram_bin_edges\",\n",
    "    \"aligned_confidence_probs\",\n",
    "    \"predicted_aligned_error\",\n",
    "    # MSA\n",
    "    \"msa\",\n",
    "    \"masked_msa\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659de6ec-d53c-47ac-9bcd-1979b364f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutation_embeddings(mutation, predictions):\n",
    "    wt, pos, mut = mutation[0], mutation[1:-1], mutation[-1]\n",
    "    idx = int(pos) - 1\n",
    "    assert idx >= 0\n",
    "\n",
    "    af_wt_idx = residue_constants.restype_order_with_x[wt]\n",
    "    af_mut_idx = residue_constants.restype_order_with_x[mut]\n",
    "\n",
    "    # Sequence\n",
    "    def as_residue(x):\n",
    "        return x[idx].astype(np.float32)\n",
    "\n",
    "    def as_protein(x):\n",
    "        return x.mean(axis=0).astype(np.float32)\n",
    "\n",
    "    # Pairwise\n",
    "    def agg_rows(x, fn):\n",
    "        return fn(x[idx, :, :], axis=0)\n",
    "\n",
    "    def agg_columns(x, fn):\n",
    "        return fn(x[:, idx, :], axis=0)\n",
    "\n",
    "    def extract_diagonal(x):\n",
    "        return x[idx, idx, :]\n",
    "\n",
    "    # MSA\n",
    "    def extract_msa_logit(value, aa_idx):\n",
    "        return value[:, idx, aa_idx]\n",
    "\n",
    "    def extract_msa_logproba(value, aa_idx):\n",
    "        return sps.log_softmax(value, axis=-1)[:, idx, aa_idx]\n",
    "\n",
    "    sequence_embeddings = {\n",
    "        \"experimentally_resolved\": predictions[\"experimentally_resolved\"],\n",
    "        \"predicted_lddt\": predictions[\"predicted_lddt\"],\n",
    "        \"msa_first_row\": predictions[\"msa_first_row\"],\n",
    "        \"single\": predictions[\"single\"],\n",
    "        \"structure_module\": predictions[\"structure_module\"],\n",
    "    }\n",
    "\n",
    "    pairwise_embeddings = {\n",
    "        \"distogram\": predictions[\"distogram\"],\n",
    "        \"aligned_confidence_probs\": predictions[\"aligned_confidence_probs\"],\n",
    "        \"pair\": predictions[\"pair\"],\n",
    "    }\n",
    "\n",
    "    msa_embeddings = {\n",
    "        \"msa\": predictions[\"msa\"],\n",
    "    }\n",
    "\n",
    "    output = {\n",
    "        # Sequence\n",
    "        \"score_plddt\": predictions[\"plddt\"][idx].item(),\n",
    "        \"score_protein_plddt\": predictions[\"plddt\"].mean().item(),\n",
    "        \"score_protein_max_predicted_aligned_error\": (\n",
    "            predictions[\"max_predicted_aligned_error\"]\n",
    "        ),\n",
    "        \"score_protein_ptm\": predictions[\"ptm\"],\n",
    "        # ...\n",
    "        **{\n",
    "            f\"features_{key}\": as_residue(value)\n",
    "            for key, value in sequence_embeddings.items()\n",
    "        },\n",
    "        # Pairwise 2D\n",
    "        \"score_predicted_aligned_error_row_mean\": (\n",
    "            predictions[\"predicted_aligned_error\"][idx, :].mean().item()\n",
    "        ),\n",
    "        \"score_predicted_aligned_error_row_max\": (\n",
    "            predictions[\"predicted_aligned_error\"][idx, :].max().item()\n",
    "        ),\n",
    "        \"score_predicted_aligned_error_col_mean\": (\n",
    "            predictions[\"predicted_aligned_error\"][:, idx].mean().item()\n",
    "        ),\n",
    "        \"score_predicted_aligned_error_col_max\": (\n",
    "            predictions[\"predicted_aligned_error\"][:, idx].max().item()\n",
    "        ),\n",
    "        \"score_predicted_aligned_error_diag\": (\n",
    "            predictions[\"predicted_aligned_error\"][idx, idx].item()\n",
    "        ),\n",
    "        # Pairwise 3D\n",
    "        **{\n",
    "            f\"features_{key}_row_mean\": agg_rows(value, np.mean)\n",
    "            for key, value in pairwise_embeddings.items()\n",
    "        },\n",
    "        **{\n",
    "            f\"features_{key}_row_max\": agg_rows(value, np.max)\n",
    "            for key, value in pairwise_embeddings.items()\n",
    "        },\n",
    "        **{\n",
    "            f\"features_{key}_col_mean\": agg_columns(value, np.mean)\n",
    "            for key, value in pairwise_embeddings.items()\n",
    "        },\n",
    "        **{\n",
    "            f\"features_{key}_col_max\": agg_columns(value, np.max)\n",
    "            for key, value in pairwise_embeddings.items()\n",
    "        },\n",
    "        **{\n",
    "            f\"features_{key}_diag\": extract_diagonal(value)\n",
    "            for key, value in pairwise_embeddings.items()\n",
    "        },\n",
    "        # MSA\n",
    "        **{\n",
    "            f\"score_msa_{process}_{agg}_{variant}\": (\n",
    "                agg_fn(process_fn(predictions[\"masked_msa\"], variant_idx))\n",
    "            )\n",
    "            for process, process_fn in [\n",
    "                (\"logits\", extract_msa_logit),\n",
    "                (\"logproba\", extract_msa_logproba),\n",
    "            ]\n",
    "            for agg, agg_fn in [\n",
    "                (\"first\", lambda x: x[0]),\n",
    "                (\"mean\", lambda x: np.mean(x, axis=0)),\n",
    "                (\"max\", lambda x: np.max(x, axis=0)),\n",
    "            ]\n",
    "            for variant, variant_idx in [\n",
    "                (\"wt\", af_wt_idx),\n",
    "                (\"mut\", af_mut_idx),\n",
    "            ]\n",
    "        },\n",
    "        **{\n",
    "            f\"features_{key}_first\": value[0, idx, :]\n",
    "            for key, value in msa_embeddings.items()\n",
    "        },\n",
    "        **{\n",
    "            f\"features_{key}_mean\": agg_columns(value, np.mean)\n",
    "            for key, value in msa_embeddings.items()\n",
    "        },\n",
    "        **{\n",
    "            f\"features_{key}_max\": agg_columns(value, np.max)\n",
    "            for key, value in msa_embeddings.items()\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8dfa0-326e-44ee-8456-a478184b6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(file):\n",
    "    df = pq.read_table(file, columns=columns).to_pandas(integer_object_nulls=True)\n",
    "\n",
    "    assert len(df) == 1\n",
    "    row = df.iloc[0].to_dict()\n",
    "    del df\n",
    "\n",
    "    for column in [\n",
    "        \"distogram\",\n",
    "        \"masked_msa\",\n",
    "        \"predicted_aligned_error\",\n",
    "        \"aligned_confidence_probs\",\n",
    "        \"msa\",\n",
    "        \"pair\",\n",
    "    ]:\n",
    "        row[column] = np.stack(\n",
    "            [np.stack(row[column][i]) for i in range(len(row[column]))]\n",
    "        )\n",
    "\n",
    "    mutations = protein_mutation_lookup[row[\"protein_id\"]]\n",
    "\n",
    "    worker_results = []\n",
    "    for mutation in mutations:\n",
    "        features = {\n",
    "            f\"alphafold_core_{key}\": value\n",
    "            for key, value in get_mutation_embeddings(mutation, row).items()\n",
    "        }\n",
    "        worker_results.append(\n",
    "            {\n",
    "                \"protein_id\": row[\"protein_id\"],\n",
    "                \"mutation\": mutation,\n",
    "            }\n",
    "            | features\n",
    "        )\n",
    "\n",
    "    return worker_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168a223-701f-4b33-9785-f2c1185426bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = worker(present_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07282351-41de-4d82-80e6-2457d40dff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d9cdf-bc05-403f-bcdd-db37e19869a2",
   "metadata": {},
   "source": [
    "### Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422ad45-7e75-4f2e-9b5b-9d3ea989d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = CPU_COUNT\n",
    "\n",
    "cpu_counts = {\n",
    "    0: 32,\n",
    "    1: 26,\n",
    "    2: 22,\n",
    "    3: 18,\n",
    "    4: 15,\n",
    "    5: 12,\n",
    "    6: 10,\n",
    "    7: 10,\n",
    "    8: 9,\n",
    "    9: 9,\n",
    "    10: 9,\n",
    "    11: 9,\n",
    "    12: 8,\n",
    "    13: 7,\n",
    "    14: 7,\n",
    "    15: 6,\n",
    "    16: 6,\n",
    "    17: 5,\n",
    "    18: 5,\n",
    "    19: 5,\n",
    "    20: 4,\n",
    "    21: 3,\n",
    "    22: 2,\n",
    "    23: 1,\n",
    "    24: 1,\n",
    "    25: 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d244b3-abef-4cd8-9dee-bc7d39bda608",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 500\n",
    "\n",
    "file_chunks = []\n",
    "for i, start in enumerate(range(0, len(present_files), chunk_size)):\n",
    "    file_chunk = present_files[start : start + chunk_size]\n",
    "    file_chunks.append((i, cpu_counts[i], file_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d47bb2-7886-4da2-9c74-30e4b41c6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(file_chunks) == TASK_COUNT, len(file_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4083d-b7cf-4d43-a2ea-12a3766d0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_chunks = file_chunks[TASK_ID - 1 : TASK_ID]\n",
    "\n",
    "len(file_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd22215-4548-4a02-9301-9aed87512db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cpu_count, file_chunk in file_chunks:\n",
    "    print(i, cpu_count)\n",
    "\n",
    "    output_file = output_dir.joinpath(\n",
    "        f\"features-shard-{i + 1:04d}-of-{TASK_COUNT:04d}.parquet\"\n",
    "    )\n",
    "    if output_file.is_file():\n",
    "        print(f\"Skipping file with {i=} and {output_file=}.\")\n",
    "        continue\n",
    "\n",
    "    writer = None\n",
    "    with concurrent.futures.ProcessPoolExecutor(cpu_count) as pool:\n",
    "        futures = pool.map(worker, file_chunk)\n",
    "        for result in tqdm(futures, total=len(file_chunk)):\n",
    "            table = pa.Table.from_pandas(pd.DataFrame(result), preserve_index=False)\n",
    "            if writer is None:\n",
    "                writer = pq.ParquetWriter(output_file, table.schema)\n",
    "            writer.write_table(table)\n",
    "    if writer is not None:\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f5ba3-9546-41c7-8b41-83e4f79c21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with output_dir.joinpath(f\"features-shard-{TASK_ID:04d}-of-{TASK_COUNT:04d}.done\").open(\n",
    "    \"wt\"\n",
    ") as fout:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6dd16-931c-412b-9b84-7699caae4371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
